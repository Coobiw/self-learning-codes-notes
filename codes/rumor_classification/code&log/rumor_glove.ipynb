{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charon/anaconda3/envs/qbw_base/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc22a72a6b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json, os\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "import math\n",
    "\n",
    "#PyTorch用的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 自然语言处理相关的包\n",
    "import re #正则表达式的包\n",
    "import jieba #结巴分词包\n",
    "from collections import Counter #搜集器，可以让统计词频更简单\n",
    "\n",
    "#绘图、计算用的程序包\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# 设置随机种子保证可复现\n",
    "import random\n",
    "SEED = 729608\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "# os python hash seed, make experiment reproducable\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "# gpu algorithom \n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "# Generator SEED\n",
    "Generator = torch.Generator()\n",
    "Generator.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词前： 最值得爱一生的五大星座排名第一名巨蟹座不畏艰辛患难与共第二名金牛座不离不弃第三名处女座不逃避困难第四名魔羯座一起吃苦第五名天蝎座真情守护被巨蟹座爱上是需要几世才能修来的好福气啊\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.375 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分词后： ['最', '值得', '爱', '一生', '的', '五大', '星座', '排名', '第一名', '巨蟹座', '不畏', '艰辛', '患难与共', '第二名', '金牛座', '不离', '不弃', '第三名', '处女座', '不', '逃避', '困难', '第四名', '魔羯座', '一起', '吃苦', '第五名', '天蝎座', '真情', '守护', '被', '巨蟹座', '爱上', '是', '需要', '几世', '才能', '修来', '的', '好福气', '啊']\n",
      "./rumor_detection_data/non_rumor.txt 包含 1849 行, 92943 个词.\n",
      "./rumor_detection_data/rumor.txt 包含 1538 行, 78645 个词.\n"
     ]
    }
   ],
   "source": [
    "pth = './rumor_detection_data'\n",
    "if not os.path.exists(pth):\n",
    "    os.makedirs(pth)\n",
    "good_file = os.path.join(pth, 'non_rumor.txt')\n",
    "bad_file = os.path.join(pth, 'rumor.txt')\n",
    "# 将文本中的标点符号过滤掉\n",
    "def filter_punc(sentence):\n",
    "    sentence = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？?、~@#￥%……&*（）：:；“”】》《-【\\][]\", \"\",sentence.strip())\n",
    "    return sentence\n",
    "\n",
    "# 扫描所有的文本，分词、建立词典，分出是谣言还是非谣言，is_filter可以过滤是否筛选掉标点符号\n",
    "def Prepare_data(good_file, bad_file, is_filter = True, threshold=3):\n",
    "    all_sentences = [] #存储所有的单词\n",
    "    pos_sentences = [] #存储非谣言\n",
    "    neg_sentences = [] #存储谣言\n",
    "    with open(good_file, 'r', encoding='utf-8') as fr:\n",
    "        for idx, line in enumerate(fr):\n",
    "            if is_filter:\n",
    "                #过滤标点符号\n",
    "                line = filter_punc(line)\n",
    "                if not idx: # 只打印第一个例子看看\n",
    "                    print('分词前：', line)\n",
    "            #分词\n",
    "            words = jieba.lcut(line)\n",
    "            if not idx: # 只打印第一个例子看看\n",
    "                print('分词后：', words)\n",
    "            if len(words) > 0:\n",
    "                all_sentences.append(words)\n",
    "                pos_sentences.append(words)\n",
    "    count = sum([len(s) for s in all_sentences])\n",
    "    print('{0} 包含 {1} 行, {2} 个词.'.format(good_file, idx+1, count))\n",
    "    with open(bad_file, 'r', encoding='utf-8') as fr:\n",
    "        for idx, line in enumerate(fr):\n",
    "            if is_filter:\n",
    "                line = filter_punc(line.strip())\n",
    "            words = jieba.lcut(line)\n",
    "            if len(words) > 0:\n",
    "                all_sentences.append(words)\n",
    "                neg_sentences.append(words)\n",
    "    print('{0} 包含 {1} 行, {2} 个词.'.format(bad_file, idx+1, sum([len(s) for s in all_sentences])-count))\n",
    "\n",
    "    return pos_sentences, neg_sentences,all_sentences\n",
    "\n",
    "\n",
    "pos_sentences, neg_sentences,all_sentences = Prepare_data(good_file, bad_file, True, threshold=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab: \n",
    "    def __init__(self,input_tokens=None,min_freq_threshold=10,special_token_tag=False):\n",
    "        if special_token_tag: # whether to use pad,begin of sentance,end of sentence,unknown tokens\n",
    "            self.pad,self.bos,self.eos,self.unk  = 0,1,2,3\n",
    "            tokens = ['<pad>','<bos>','<eos>','<unk>'] # ?\n",
    "            self.special_tokens = ['<pad>','<bos>','<eos>','<unk>']\n",
    "        else:\n",
    "            self.unk = 0\n",
    "            tokens = ['<unk>']\n",
    "            self.special_tokens = ['<unk>']\n",
    "        \n",
    "        # when load, we can just initialze a nearly empty Vocab class\n",
    "        # then load .pkl file to give the value of token2idx,idx2token\n",
    "        if input_tokens is None: \n",
    "            return \n",
    "            \n",
    "        # hashmap to count the tokens(key:token,value:freq)\n",
    "        assert len(input_tokens),'0 length is not allowed'\n",
    "        if isinstance(input_tokens[0],list): \n",
    "            input_tokens = [token for sentence in input_tokens for token in sentence if token not in self.special_tokens]\n",
    "            tokens_freq = Counter(input_tokens)\n",
    "        else:\n",
    "            tokens_freq = Counter(input_tokens) \n",
    "        tokens_freq = sorted(tokens_freq.items(),key=lambda x:x[0]) # sort the tokens_freq dict by dictionary order\n",
    "        tokens_freq = sorted(tokens_freq,key=lambda x:x[1],reverse=True) # sort the tokens_freq dict by freq order\n",
    "        tokens_freq = dict(tokens_freq)\n",
    "        # print(tokens_freq)\n",
    "        \n",
    "        # establish two hashmaps to transform index to token or reverse transform\n",
    "        self.idx2token = []\n",
    "        self.token2idx = dict()\n",
    "\n",
    "        # filter the tokens whose freq is letter than min_freq_threshold\n",
    "        tokens += list(filter(lambda x:tokens_freq[x]>min_freq_threshold,tokens_freq.keys()))\n",
    "        # tokens += [token for token,freq in tokens_freq.items() if freq>=min_freq_threshold]\n",
    "\n",
    "        # add the token to the two hashmaps\n",
    "        i = 0 # 0 index is unknown token\n",
    "        for token in tokens:\n",
    "            self.idx2token.append(token)\n",
    "            self.token2idx[token] = i\n",
    "            i += 1\n",
    "        assert len(self.idx2token) == len(self.token2idx),(len(self.idx2token),len(self.token2idx))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx2token)\n",
    "    \n",
    "    def __getitem__(self,tokens): \n",
    "        '''\n",
    "        input : tokens(single char or list/tuple) \n",
    "        output : idx(then torch.nn.Embedding automatically transform to one-hot code)\n",
    "        '''\n",
    "        if (not isinstance(tokens,tuple)) and (not isinstance(tokens,list)):\n",
    "            return self.token2idx.get(tokens,self.unk)\n",
    "        else:\n",
    "            # recursive call the __getitem__,until the token is a single char\n",
    "            # use this strategy, we can process higher dim tensor such as :\n",
    "            # [[a,b,c,...]](shape:[n1,n2]) or even [[[a,b,c],[d,e,f]]](shape:[n1,n2,n3])\n",
    "            # the return shape is the same as the input\n",
    "            return [self.__getitem__(token) for token in tokens]\n",
    "    \n",
    "    def to_tokens(self,indices):\n",
    "        '''\n",
    "            input the indices\n",
    "            output the corresponding tokens\n",
    "        '''\n",
    "        if (not isinstance(indices,tuple)) and (not isinstance(indices,list)):\n",
    "            return self.idx2token[indices]\n",
    "        else:\n",
    "            return [self.to_tokens(index) for index in indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample(sentences,vocab):\n",
    "    '''\n",
    "    subsample the sences to reduce the impace of the much high-frequence but less-message tokens like \"the\",\"a\",\"in\" and so on\n",
    "    '''\n",
    "    # 排除未知词元'<unk>'\n",
    "    sentences_flatten = [token for line in sentences for token in line if vocab[token] != vocab.unk]\n",
    "    counter = Counter(sentences_flatten)\n",
    "    num_tokens = sum(counter.values()) # the sum number of the words/tokens\n",
    "\n",
    "    def keep_func(token,t=1e-4): # t is a hyper-parameter\n",
    "        # when freq(token) > t,it will be definitely dropped,else the higher freq,the higher prob to be dropped\n",
    "        freq = counter[token] / num_tokens\n",
    "        return (random.uniform(0, 1) > max((1 - math.sqrt(t / freq),0)))\n",
    "\n",
    "    subsampled = []\n",
    "    for line in sentences:\n",
    "        temp = []\n",
    "        for token in line:\n",
    "            if token in counter.keys() and keep_func(token):\n",
    "                temp.append(token)\n",
    "        subsampled.append(temp)\n",
    "    return subsampled,counter\n",
    "\n",
    "def compare_counts(token):\n",
    "    return (f'\"{token}\"的数量：'\n",
    "            f'之前={sum([l.count(token) for l in sentences])}, '\n",
    "            f'之后={subsampled.count(token)}')\n",
    "\n",
    "# get the centers and contexts token to do the skip-gram language model\n",
    "def get_centers_and_contexts(corpus, max_window_size):\n",
    "    \"\"\"return the center token and the corresponding context token\"\"\"\n",
    "    centers, contexts = [], []\n",
    "    for line in corpus: # corpus shape: [num_sentence,num_tokens_per_sentence]\n",
    "        # if length of sentence is less than 2, cannot compose the center-context pair\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        centers += line\n",
    "        for i in range(len(line)):  # center_idx = i\n",
    "            # window_size = random.randint(1, max_window_size) # randomly generate the window_size\n",
    "            window_size = max(1,max_window_size)\n",
    "            indices = list(range(max(0, i - window_size),\n",
    "                                 min(len(line), i + 1 + window_size))) # get the context token in the window(both left and right)\n",
    "            # remove the center token\n",
    "            indices.remove(i)\n",
    "            contexts.append([(line[idx],abs(idx-i)) for idx in indices])\n",
    "    return centers, contexts\n",
    "\n",
    "def coappearence_computation(vocab_size,centers,contexts,use_distance_weight=False):\n",
    "    coappearence_matrix = torch.zeros((vocab_size,vocab_size))\n",
    "    if use_distance_weight:\n",
    "        coappearence_matrix_2 = torch.zeros((vocab_size,vocab_size))\n",
    "    lc = len(centers)\n",
    "    for i in range(lc):\n",
    "        row = centers[i]\n",
    "        columns = contexts[i]\n",
    "        for col in columns:\n",
    "            # print(col)\n",
    "            coappearence_matrix[row,col[0]] += 1.\n",
    "            if use_distance_weight:\n",
    "                coappearence_matrix_2[row,col[0]] +=1. / col[1]\n",
    "    if use_distance_weight:\n",
    "        return coappearence_matrix,coappearence_matrix_2\n",
    "    else:\n",
    "        return coappearence_matrix\n",
    "\n",
    "\n",
    "\n",
    "def batchify(data):\n",
    "    '''\n",
    "    if want to batchify the data, we need:\n",
    "        - padding the data because the num_context_per_center is not the same\n",
    "        - generate the mask so that the padding part will not be included in the loss_func computation\n",
    "    '''\n",
    "    max_len = max([len(c) for _,c,_ in data]) \n",
    "    centers,all_contexts,all_masks,all_labels = [],[],[],[]\n",
    "    for i,item in enumerate(data):\n",
    "        center,context,label = item\n",
    "        centers.append(center)\n",
    "        cur_len = len(context) \n",
    "        all_contexts.append(context + [0]*(max_len - cur_len))\n",
    "        all_masks.append([1.]*cur_len + [0.]*(max_len-cur_len))\n",
    "        all_labels.append(label + [1.]*(max_len-len(label))) # can't pad 0,because log(0) = -inf\n",
    "    \n",
    "    centers = torch.tensor(centers).reshape(-1,1)\n",
    "    all_contexts = torch.tensor(all_contexts)\n",
    "    all_masks = torch.tensor(all_masks)\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    return centers,all_contexts,all_masks,all_labels\n",
    "\n",
    "def batchify2(data):\n",
    "    '''\n",
    "    if want to batchify the data, we need:\n",
    "        - padding the data because the num_context_per_center is not the same\n",
    "        - generate the mask so that the padding part will not be included in the loss_func computation\n",
    "    '''\n",
    "    max_len = max([len(c) for _,c,_,_ in data]) \n",
    "    centers,all_contexts,all_masks,all_labels,all_weights = [],[],[],[],[]\n",
    "    for i,item in enumerate(data):\n",
    "        center,context,label,weight = item\n",
    "        centers.append(center)\n",
    "        cur_len = len(context) \n",
    "        all_contexts.append(context + [0]*(max_len - cur_len))\n",
    "        all_masks.append([1.]*cur_len + [0.]*(max_len-cur_len))\n",
    "        all_labels.append(label + [1.]*(max_len-len(label))) # can't pad 0,because log(0) = -inf\n",
    "        all_weights.append(weight + [1.]*(max_len-len(weight)))\n",
    "    \n",
    "    centers = torch.tensor(centers).reshape(-1,1)\n",
    "    all_contexts = torch.tensor(all_contexts)\n",
    "    all_masks = torch.tensor(all_masks)\n",
    "    all_labels = torch.tensor(all_labels)\n",
    "    all_weights = torch.tensor(all_weights)\n",
    "    return centers,all_contexts,all_masks,all_labels,all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_ptb(bs,max_window_size,sentences,use_distance_weight=False,load_vocab=True,save_dir=None):\n",
    "    if load_vocab:\n",
    "        vocab = Vocab()\n",
    "        with open(os.path.join(save_dir,'token2idx.pkl'),'rb') as f:\n",
    "            vocab.token2idx = pickle.load(f)\n",
    "        with open(os.path.join(save_dir,'idx2token.pkl'),'rb') as f:\n",
    "            vocab.idx2token = pickle.load(f)\n",
    "    else:\n",
    "        vocab = Vocab(sentences,min_freq_threshold=3,special_token_tag=False)\n",
    "    print(f'词表大小为：{len(vocab)}')\n",
    "\n",
    "\n",
    "    # subsampling \n",
    "    # subsampled, counter = subsample(sentences, vocab)\n",
    "\n",
    "    subsampled = sentences\n",
    "\n",
    "    # transfrom token to idx(getitem)\n",
    "    corpus = [vocab[line] for line in subsampled]\n",
    "\n",
    "    # generate center-context pair\n",
    "    all_centers, all_contexts = get_centers_and_contexts(corpus, max_window_size)\n",
    "\n",
    "    # compute the co-appearence matrix\n",
    "    if use_distance_weight:\n",
    "        coappearence_matrix,coappearence_matrix_2 = coappearence_computation(len(vocab),all_centers,all_contexts,use_distance_weight=use_distance_weight)\n",
    "    else:\n",
    "        coappearence_matrix = coappearence_computation(len(vocab),all_centers,all_contexts,use_distance_weight=use_distance_weight)\n",
    "\n",
    "    class PTB_DATASET(Dataset):\n",
    "        def __init__(self, centers, contexts,use_distance_weight,coappearence_matrix):\n",
    "            assert len(centers) == len(contexts) ,f'({len(centers)},{len(contexts)})'\n",
    "            self.centers = centers\n",
    "            self.contexts = []\n",
    "            for context in contexts:\n",
    "                self.contexts.append([c[0] for c in context])\n",
    "            if use_distance_weight:\n",
    "                self.coappearence_matrix,self.coappearence_matrix_2 = coappearence_matrix\n",
    "            else:\n",
    "                self.coappearence_matrix = coappearence_matrix\n",
    "            self.tag = use_distance_weight\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            center = self.centers[index]\n",
    "            contexts = self.contexts[index]\n",
    "            if self.tag:\n",
    "                label = self.coappearence_matrix_2[center,contexts].tolist()\n",
    "            else:\n",
    "                label = self.coappearence_matrix[center,contexts].tolist()\n",
    "            if not self.tag:\n",
    "                return (self.centers[index], self.contexts[index],label)\n",
    "            return (self.centers[index], self.contexts[index],label,self.coappearence_matrix[center,contexts].tolist())\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.centers)\n",
    "    \n",
    "    if not use_distance_weight:\n",
    "        ptb_dataset = PTB_DATASET(all_centers,all_contexts,use_distance_weight,coappearence_matrix)\n",
    "        dataloader = DataLoader(\n",
    "            ptb_dataset, batch_size=bs, shuffle=True,\n",
    "            collate_fn=batchify, num_workers=4)\n",
    "    else:\n",
    "        ptb_dataset = PTB_DATASET(all_centers,all_contexts,use_distance_weight,(coappearence_matrix,coappearence_matrix_2))\n",
    "        dataloader = DataLoader(\n",
    "            ptb_dataset, batch_size=bs, shuffle=True,\n",
    "            collate_fn=batchify2, num_workers=4)\n",
    "    \n",
    "    return dataloader,vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m,mode='zero'):\n",
    "    if type(m) == nn.Embedding:\n",
    "        if mode =='xavier':\n",
    "            nn.init.xavier_normal_(m.weight)\n",
    "        else:\n",
    "            nn.init.zeros_(m.weight)\n",
    "\n",
    "class GloVe(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding_size) -> None:\n",
    "        super(GloVe,self).__init__()\n",
    "        self.context = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.center = nn.Embedding(vocab_size,embedding_size)\n",
    "        self.context_bias = nn.Embedding(vocab_size,1)\n",
    "        self.center_bias = nn.Embedding(vocab_size,1)\n",
    "        init_weights(self.context,mode='xavier')\n",
    "        init_weights(self.center,mode='xavier')\n",
    "        init_weights(self.center_bias)\n",
    "        init_weights(self.context_bias)\n",
    "\n",
    "    \n",
    "    def forward(self,center, all_contexts): # input.shape: B,N,vocab_size\n",
    "        bs,max_len = all_contexts.shape\n",
    "        contexts = self.context(all_contexts) # shape (B,N_context,embedding_size)\n",
    "        centers = self.center(center) # shape (B,1,embedding_size)\n",
    "        contexts_bias = self.context_bias(all_contexts) # shape (B,N_context,1)\n",
    "        centers_bias = self.center_bias(center) # shape (B,1,1)\n",
    "        similarity = centers @ contexts.transpose(1,2) # shape:[B,1,N_context]\n",
    "        similarity = similarity.reshape(bs,max_len)\n",
    "        centers_bias = centers_bias.reshape(bs,1)\n",
    "        contexts_bias = contexts_bias.reshape(bs,max_len)\n",
    "        output = contexts_bias + similarity + centers_bias\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.sum = 0.\n",
    "        self.avg = 0.\n",
    "    \n",
    "    def update(self,n,val,multiply=True):\n",
    "        self.count += n\n",
    "        if multiply:\n",
    "            self.sum += n*val\n",
    "        else:\n",
    "            self.sum += val\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class Log_MSELoss(nn.Module):\n",
    "    # Log + MSELoss **with mask**\n",
    "    def __init__(self,c=10,alpha=0.75):\n",
    "        super().__init__()\n",
    "        self.c = c\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, inputs, target_1,target_2, mask):\n",
    "        log_target = torch.log(target_1)\n",
    "        loss = ((inputs - log_target)**2) * self.weight_func(target_2) * mask \n",
    "        loss = loss.sum(dim=1)\n",
    "        loss = loss / mask.sum(dim=1)\n",
    "        loss = loss.mean(dim=0)\n",
    "        return loss\n",
    "    \n",
    "    def weight_func(self,target):\n",
    "        weight = torch.zeros_like(target)\n",
    "        weight[target>=self.c] = 1.\n",
    "        weight[target<self.c] = (target[target<self.c]/self.c)**self.alpha\n",
    "        return weight\n",
    "\n",
    "def train_one_epoch(model,optimizer,device,data_iter,loss,use_distance_weight):\n",
    "    train_loss = AverageMeter()\n",
    "    for batch in data_iter:\n",
    "        if use_distance_weight:\n",
    "            center,contexts,mask,label,weight = [data.to(device) for data in batch]\n",
    "        else:\n",
    "            center,contexts,mask,label = [data.to(device) for data in batch]\n",
    "        pred = model(center,contexts)\n",
    "        \n",
    "        if use_distance_weight:\n",
    "            t_loss = loss(pred,label,weight,mask)\n",
    "        else:\n",
    "            t_loss = loss(pred,label,label,mask)\n",
    "        optimizer.zero_grad()\n",
    "        t_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.update(n=center.shape[0],val=t_loss.item(),multiply=True)\n",
    "    \n",
    "    return train_loss.avg\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_similar_tokens(model,query_token, k, vocab): \n",
    "    '''\n",
    "    in GloVe, x_{ij} = x_{ji}\n",
    "    so center_embedding and context_embedding are symmetric in math\n",
    "    but because the two are not same initialized\n",
    "    so they have a little difference\n",
    "    **This difference help the model to be robust**(like one model ensemble method——use different initialization method)\n",
    "    '''\n",
    "    model.eval()\n",
    "    W = model.center.weight.data\n",
    "    W2 = model.context.weight.data\n",
    "    W = W + W2\n",
    "    x = W[vocab[query_token]]\n",
    "    # 计算余弦相似性。增加1e-9以获得数值稳定性\n",
    "    cos = torch.mv(W, x) / torch.sqrt(torch.sum(W * W, dim=1) *\n",
    "                                      torch.sum(x * x) + 1e-9)\n",
    "    topk = torch.topk(cos, k=k+1)[1].cpu().numpy().astype('int32')\n",
    "    for i in topk[1:]:  # 删除输入词\n",
    "        print(f'cosine sim={float(cos[i]):.3f}: {vocab.to_tokens(i)}')\n",
    "\n",
    "\n",
    "def main(sentences):\n",
    "    for_mlp = True\n",
    "    use_distance_weight = True\n",
    "    bs, max_window_size = 512, 5\n",
    "\n",
    "    if not for_mlp:\n",
    "        save_dir = './model_vocab_glove'\n",
    "    else:\n",
    "        save_dir = './model_vocab_glove_for_mlp_dw' if use_distance_weight else './model_vocab_glove_for_mlp'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    data_iter, vocab = load_data_ptb(bs, max_window_size,sentences,use_distance_weight=use_distance_weight,load_vocab=True,save_dir=save_dir)\n",
    "\n",
    "    lr = 1e-4\n",
    "    num_epochs = 20\n",
    "    embedding_size_lst = [16,32,64,96]\n",
    "    \n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    for embedding_size in embedding_size_lst:\n",
    "        model = GloVe(len(vocab),embedding_size).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        loss = Log_MSELoss().to(device)\n",
    "        \n",
    "        loss_decription = 0.\n",
    "        pbar = trange(num_epochs)\n",
    "        for i in pbar:\n",
    "            loss_decription = train_one_epoch(model,optimizer,device,data_iter,loss,use_distance_weight)\n",
    "            description = f'Epoch: {i+1}  Train_Loss:{loss_decription:.3f}'\n",
    "            pbar.set_description(description)\n",
    "\n",
    "        # save model\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        with open(os.path.join(save_dir,f'model_{embedding_size}.pth'),'wb') as f:\n",
    "            torch.save(model,f)\n",
    "    \n",
    "        # with open(os.path.join(save_dir,'token2idx.pkl'),'wb') as f:\n",
    "        #     pickle.dump(vocab.token2idx,f)\n",
    "        \n",
    "        # with open(os.path.join(save_dir,'idx2token.pkl'),'wb') as f:\n",
    "        #     pickle.dump(vocab.idx2token,f)\n",
    "        print((model.context.weight.data + model.center.weight.data)[:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词表大小为：6690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20  Train_Loss:0.560: 100%|██████████| 20/20 [00:27<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4441,  1.4483, -1.4588, -1.4445, -1.4577, -1.4462, -1.4425, -1.4295,\n",
      "         -1.4579, -1.4412,  1.4518, -1.4610,  1.4581, -1.4506,  1.4491, -1.4515],\n",
      "        [-1.2886,  1.2937, -1.2390, -1.3264, -1.2325, -1.2891, -1.2800, -1.2687,\n",
      "         -1.2489, -1.3152,  1.2468, -1.2409,  1.2261, -1.2732,  1.2672, -1.2608]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20  Train_Loss:0.391: 100%|██████████| 20/20 [00:29<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1010,  1.1176,  1.1196,  1.1208, -1.1125,  1.1225,  1.1094,  1.1173,\n",
      "          1.1097,  1.1097,  1.1305, -1.1171, -1.1195,  1.1175, -1.1098, -1.1200,\n",
      "          1.1228, -1.1108,  1.1209, -1.1238, -1.1287, -1.1086, -1.1093, -1.1236,\n",
      "          1.1143,  1.1261, -1.1137, -1.1078,  1.1223, -1.1071,  1.1168,  1.1119],\n",
      "        [ 0.9426,  0.9008,  0.8807,  0.9026, -0.9156,  0.8871,  0.9595,  0.8916,\n",
      "          0.9273,  0.9106,  0.8688, -0.9312, -0.8899,  0.9113, -0.9063, -0.9167,\n",
      "          0.9229, -0.9157,  0.8989, -0.8860, -0.8995, -0.9329, -0.9078, -0.8758,\n",
      "          0.9455,  0.8740, -0.9222, -0.9161,  0.9076, -0.9589,  0.9082,  0.9182]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20  Train_Loss:0.377: 100%|██████████| 20/20 [00:27<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7982,  0.8012,  0.8044,  0.7948,  0.7982,  0.8015, -0.7968, -0.7921,\n",
      "         -0.7997, -0.7920,  0.8124, -0.7905,  0.8016, -0.7939, -0.7950, -0.7900,\n",
      "          0.7959, -0.7885,  0.7945, -0.8077,  0.8030,  0.7922, -0.8011,  0.8012,\n",
      "         -0.8092, -0.7965, -0.7950,  0.7957,  0.7973, -0.7963, -0.8014,  0.7890,\n",
      "          0.8018, -0.8003,  0.7998, -0.7942,  0.8041,  0.8022, -0.7984, -0.7994,\n",
      "         -0.7981, -0.7919, -0.7909, -0.7974, -0.7893, -0.8071, -0.8017, -0.7994,\n",
      "          0.7923, -0.7945, -0.7983, -0.7917,  0.7966,  0.7968,  0.7940, -0.8035,\n",
      "          0.8097, -0.8041,  0.7994, -0.8050,  0.7955,  0.7979, -0.8024, -0.7959],\n",
      "        [-0.6435,  0.6203,  0.6171,  0.6874,  0.6332,  0.6296, -0.6724, -0.6831,\n",
      "         -0.6689, -0.7053,  0.6231, -0.6753,  0.6398, -0.6758, -0.6578, -0.6624,\n",
      "          0.6746, -0.6840,  0.6808, -0.6581,  0.6264,  0.6651, -0.6485,  0.6458,\n",
      "         -0.5755, -0.6417, -0.6580,  0.6423,  0.6452, -0.6419, -0.6538,  0.6920,\n",
      "          0.6252, -0.6662,  0.5898, -0.6615,  0.6491,  0.6514, -0.6577, -0.6429,\n",
      "         -0.6389, -0.6848, -0.6785, -0.6707, -0.6787, -0.6229, -0.6181, -0.6583,\n",
      "          0.6855, -0.6567, -0.6598, -0.6519,  0.6327,  0.6660,  0.6732, -0.6278,\n",
      "          0.6210, -0.6054,  0.6466, -0.6271,  0.6599,  0.6430, -0.6354, -0.6771]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20  Train_Loss:0.363: 100%|██████████| 20/20 [00:27<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.6618,  0.6528, -0.6595, -0.6607, -0.6642,  0.6548,  0.6448,  0.6608,\n",
      "          0.6509,  0.6568, -0.6456,  0.6564, -0.6576,  0.6438, -0.6531,  0.6513,\n",
      "         -0.6543,  0.6554,  0.6571,  0.6561, -0.6558,  0.6569,  0.6453,  0.6568,\n",
      "          0.6518, -0.6528, -0.6639, -0.6516,  0.6492, -0.6592, -0.6553, -0.6447,\n",
      "         -0.6525, -0.6591, -0.6541,  0.6161, -0.6580,  0.6561, -0.6612, -0.6452,\n",
      "         -0.6565, -0.6528, -0.6609, -0.6534,  0.6544,  0.6494,  0.6543,  0.6519,\n",
      "         -0.6634,  0.6481, -0.6533, -0.6516,  0.6505, -0.6547,  0.6581,  0.6468,\n",
      "          0.6531,  0.6521, -0.6563, -0.6544,  0.6553,  0.6624, -0.6537,  0.6619,\n",
      "          0.6516, -0.6589, -0.6552,  0.6592, -0.6490, -0.6566,  0.6571, -0.6532,\n",
      "          0.6566, -0.6555, -0.6566,  0.6684, -0.6583, -0.6550,  0.6478, -0.6618,\n",
      "          0.6627,  0.6566,  0.6673,  0.6609, -0.6561,  0.6412,  0.6554,  0.6619,\n",
      "          0.6529,  0.6607,  0.6454,  0.6506,  0.6534, -0.6511, -0.6420, -0.6527],\n",
      "        [-0.5012,  0.5530, -0.5052, -0.5294, -0.5204,  0.5145,  0.5270,  0.5510,\n",
      "          0.5414,  0.5387, -0.5525,  0.5409, -0.4907,  0.5303, -0.5299,  0.5435,\n",
      "         -0.5292,  0.5130,  0.5423,  0.5381, -0.5063,  0.4954,  0.5987,  0.5547,\n",
      "          0.5492, -0.5601, -0.4876, -0.5213,  0.5474, -0.5186, -0.5583, -0.5816,\n",
      "         -0.5647, -0.5101, -0.5769,  0.6032, -0.5303,  0.5528, -0.5009, -0.5331,\n",
      "         -0.5158, -0.5255, -0.5105, -0.5385,  0.5754,  0.5456,  0.5562,  0.5720,\n",
      "         -0.5160,  0.5680, -0.5445, -0.5981,  0.5331, -0.5765,  0.5049,  0.5763,\n",
      "          0.5265,  0.5411, -0.5186, -0.5375,  0.5181,  0.5218, -0.5560,  0.5041,\n",
      "          0.5425, -0.4998, -0.5722,  0.4974, -0.5469, -0.5194,  0.5340, -0.4947,\n",
      "          0.5180, -0.5085, -0.5134,  0.5195, -0.5228, -0.5291,  0.5789, -0.5469,\n",
      "          0.4987,  0.5183,  0.5236,  0.5124, -0.5693,  0.5444,  0.5146,  0.5338,\n",
      "          0.5288,  0.4733,  0.5698,  0.5315,  0.5145, -0.5937, -0.5720, -0.5329]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main(sentences=all_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('qbw_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "931916ec1e9018a72ab9e17be70c974d037672808d5f8fd77a6dc58db3f6bcd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
